%%
% 摘要信息
% 本文档中前缀"c-"代表中文版字段, 前缀"e-"代表英文版字段
% 摘要内容应概括地反映出本论文的主要内容，主要说明本论文的研究目的、内容、方法、成果和结论。要突出本论文的创造性成果或新见解，不要与引言相 混淆。语言力求精练、准确，以 300—500 字为宜。
% 在摘要的下方另起一行，注明本文的关键词（3—5 个）。关键词是供检索用的主题词条，应采用能覆盖论文主要内容的通用技术词条(参照相应的技术术语 标准)。按词条的外延层次排列（外延大的排在前面）。摘要与关键词应在同一页。
% modifier: 黄俊杰(huangjj27, 349373001dc@gmail.com)
% update date: 2017-04-15
%%

\cabstract{
    % 摘要应概括论文的主要信息，
    % 应具有独立性和自含性，即不阅读论文的全文，就能获得必要的信息。摘要内容一般应包括研究目的、内容、方法、成果和结论，要突出论文的创造性成果或新见解，不要与绪论相混淆。语言力求精练、准确，以300-500字为宜。关键词是供检索用的主题词条，应体现论文特色，具有语义性，在论文中有明确的出处，并应尽量采用《汉语主题词表》或各专业主题词表提供的规范词。关键词与摘要应在同一页，在摘要的下方另起一行注明，一般列3-5个，按词条的外延层次排列（外延大的排在前面）。

    % 随着大数据处理、大规模智能模型训练、强化学习等多样化、高负载的计算需求成为学术界和产业界关注的焦点之一，作为计算基础设施的分布式计算框架（如Mapreduce, Spark, Ray）正在得到更多的关注和更广泛的应用。
    分布式计算框架（如Mapreduce, Spark, Ray）是一种复杂的平台软件，支持用户运行分布式计算任务。计算框架除了为用户调度任务，还需要高效地管理和利用计算集群的物理资源。
    大数据处理、大规模智能模型训练等快速增长的计算需求，逐渐受制于集群有限的硬件性能和资源利用：一方面，高性能计算（HPC）集群正在得到更广泛的部署和使用，其硬件优势仍有待挖掘。这类集群拥有的新型高性能网络，明显地区别于传统集群。
    以智能网卡为硬件基础，高性能计算机能够在无中央处理器（CPU）的介入下，对机器内存直接读写以传输数据。这种被称为远程直接内存访问（RDMA）的传输机制，相比以太网具有低占用、低延迟、高带宽等技术优势。
    另一方面，作为基础设施的软件框架，则面临无法高效使用硬件资源的挑战：当前，大多数分布式计算框架仍然缺乏对高性能硬件的支持，特别是无法充分利用集群中的高速网络资源。
    
    近年来，出现了以强化学习、流处理为代表的新型计算任务。其任务逻辑更加灵活、复杂，调度机制也不再限于任务并行、数据并行等静态方法。为了支持更灵活的任务调度及数据移动，计算框架需要高效的数据管理机制，特别是针对分布在集群内存空间中的对象数据。
    分布式内存对象存储Plasma是新型计算框架Ray的内存管理模块。然而，Plasma未能直接利用HPC高速网络的硬件优势，因此无法在任务间低时延地传递对象数据。
    为此，通过研发基于RDMA的高性能数据传输机制，我们能将现代网络的硬件优势转化为Ray系统整体的性能优势。
    
    在本研究中，我们首先测试和分析了其基于以太网和套接字传输数据而导致的性能瓶颈。然后，在高性能集群上，我们提出了一种支持RDMA特性的高吞吐对象传输机制。
    该机制针对大型对象数据，提出了基于单边读语义的传输协议，实现了用户态的内存零拷贝。并且，该机制能够在运行时，根据数据大小动态地选择传输协议，以获得最佳性能。进一步，我们基于并行计算范式MPI构造了分布式、可扩展的多节点传输性能测试。
    在实验中，我们确定了传输协议的最优参数，并且展示了在天河高性能集群上，优化后的内存平台在常见大小的对象传输中实现至多7倍于原实现的吞吐率。
}
% 中文关键词(每个关键词之间用“，”分开,最后一个关键词不打标点符号。)
\ckeywords{数据传输，高性能网络，RDMA，键值对存储，分布式缓存}

\eabstract{
    % 英文摘要及关键词内容应与中文摘要及关键词内容相同。中英文摘要及其关键词各置一页内。
 
    Distributed computing frameworks (e.g., Mapreduce, Spark, Ray) are complicated platform software supporting distributed tasks. 
    Besides scheduling users' tasks, frameworks are responsible for efficiently utilizing the resources of a cluster.
    In the context of big data and large models, hardware performance and resource usage have long been limiting the scale of computation.
    On the one hand, high-performance computing (HPC) clusters are widely deployed now. 
    These systems have distinct network architecture. With hardware support from smart NICs, HPC machines can directly read/write remote memory for communication.
    The transmission technique called Remote Direct Memory Access (RDMA) presents low occupancy, low latency, and high bandwidth as strengths that Ethernet doesn't own. 
    On the other hand, most recent frameworks cannot exploit high-performance hardware, especially high-speed networks with RDMA.

    Novel tasks such as reinforcement learning and stream processing have emerged recently. These tasks are flexible and complex that they cannot be scheduled simply with task or data parallelism.
    Therefore, frameworks now need efficient cluster memory management to support a better scheduling scheme. Plasma is the distributed memory management module of a popular framework called Ray.
    However, it doesn't exploit the advanced features of the HPC network, thus not able to transfer data with low latency. 
    By introducing a novel, high-performance transmission scheme, we manage to turn features of modern network into better performance of Plasma and Ray.
    
    In this work, we first identify the network bottleneck of Plasma with benchmark and analysis. Then, we propose this scheme with hybrid transfer protocols.
    Besides the usual send/recv protocol, it chooses a one-sided read protocol for transferring
    large objects with zero-copy. For the best performance, we further implement a simple yet effective strategy to switch between the two protocols, given the sizes of the objects. 
    Finally, we construct a distributed, scalable MPI benchmark for testing the transmission overhead. 
    Experiments demonstrate that, with the best-selected parameter, our improved memory store can achieve up to 7x throughput on our Tianhe HPC cluster.
}
% 英文文关键词(每个关键词之间用,分开, 最后一个关键词不打标点符号。)
\ekeywords{data transfer, high-performance network, RDMA, key-value store, distributed memory}