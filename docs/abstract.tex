%%
% 摘要信息
% 本文档中前缀"c-"代表中文版字段, 前缀"e-"代表英文版字段
% 摘要内容应概括地反映出本论文的主要内容，主要说明本论文的研究目的、内容、方法、成果和结论。要突出本论文的创造性成果或新见解，不要与引言相 混淆。语言力求精练、准确，以 300—500 字为宜。
% 在摘要的下方另起一行，注明本文的关键词（3—5 个）。关键词是供检索用的主题词条，应采用能覆盖论文主要内容的通用技术词条(参照相应的技术术语 标准)。按词条的外延层次排列（外延大的排在前面）。摘要与关键词应在同一页。
% modifier: 黄俊杰(huangjj27, 349373001dc@gmail.com)
% update date: 2017-04-15
%%

\cabstract{
    % 摘要应概括论文的主要信息，
    % 应具有独立性和自含性，即不阅读论文的全文，就能获得必要的信息。摘要内容一般应包括研究目的、内容、方法、成果和结论，要突出论文的创造性成果或新见解，不要与绪论相混淆。语言力求精练、准确，以300-500字为宜。关键词是供检索用的主题词条，应体现论文特色，具有语义性，在论文中有明确的出处，并应尽量采用《汉语主题词表》或各专业主题词表提供的规范词。关键词与摘要应在同一页，在摘要的下方另起一行注明，一般列3-5个，按词条的外延层次排列（外延大的排在前面）。

    随着大数据处理、大规模智能模型训练、强化学习等多样化、高负载的计算需求成为学术界和产业界关注的焦点之一，作为计算基础设施的分布式计算框架（例如Mapreduce, Spark, Ray）
    正在得到更多的关注和更广泛的应用。通常，计算框架软件负责为用户调度计算任务，同时管理和最大限度地利用计算集群的物理资源。
    上述场景所产生的快速增长的计算需求，正在使计算集群的性能愈发捉襟见肘：一方面，高性能计算(HPC)集群正在取代廉价的计算机器以应对高强度的计算。值得注意的是，前者所拥有的新型高性能网络，明显地区别于传统集群。
    以智能网卡为硬件基础，高性能计算机能够在无中央处理器（CPU）的介入下，对机器内存直接读写以传输数据。这种被称为远程直接内存访问（RDMA）的传输机制，相比以太网具有低占用、低延迟、高带宽等技术优势。
    另一方面，作为基础设施的软件框架，也在面临严峻的性能挑战：当前大多数分布式计算框架仍然缺乏对高性能硬件的支持，特别是无法充分利用集群中的高速网络资源。
    
    Ray作为面向强化学习等新型计算任务的分布式计算框架，同样存在着上述性能瓶颈。为此，通过设计高效、高性能的通信机制，我们能将现代网络的硬件优势转化为Ray系统整体的性能优势。
    本研究从该框架的核心组件：分布式内存对象数据库Plasma入手，首先测试和分析了其基于以太网和套接字传输数据而导致的性能瓶颈。然后，在高性能集群上，我们提出了一种支持RDMA特性的高吞吐对象传输机制。
    该机制针对大型数据对象，提出了基于单边读语义的传输协议，实现了用户态的内存零拷贝。并且该机制能够在运行时，根据数据大小动态地选择传输协议，以获得最佳性能。进一步，我们基于并行计算范式MPI构造了分布式、可扩展的多节点传输性能测试。
    在实验中，我们确定了传输协议的最优参数，并且展示了在天河高性能集群上，优化后的内存平台在常见大小的对象传输中实现至多7倍于原实现的吞吐率。
}
% 中文关键词(每个关键词之间用“，”分开,最后一个关键词不打标点符号。)
\ckeywords{数据传输，高性能网络，RDMA，键值对数据库，分布式缓存}

\eabstract{
    % 英文摘要及关键词内容应与中文摘要及关键词内容相同。中英文摘要及其关键词各置一页内。
 
    Diverse and heavy computing workloads, including big data processing, large-scale model training, and reinforcement learning (RL),
    have increasingly drawn attention from the industrial and academic worlds. Distributed computing frameworks (Mapreduce, Spark, Ray, etc.) as the infrastructure
    recently also gained more attention and applications. Frameworks are responsible for scheduling users' tasks and efficiently utilizing 
    the physical resources of the clusters. The growing need for computation that comes with the mentioned workloads challenges the performance of these machines. On the one hand, 
    high-performance computing (HPC) clusters are replacing the traditional, cheap ones to handle intensified computation. These systems have distinct network architecture.
    With hardware support from smart NICs, HPC machines can directly read/write remote memory for communication.
    The transmission technique called Remote Direct Memory Access (RDMA) presents low occupancy, low latency, and high bandwidth as strengths that Ethernet doesn't own. On the other hand, the underlying software
    faces severe performance problems as well: most recent distributed computing frameworks cannot exploit high-performance hardware, especially high-speed networks with RDMA.

    The above performance gap exists in Ray, a novel framework targeting emerging computing tasks such as RL. To handle this, we manage to turn advanced features of RDMA into
    better performance, by introducing a novel, high-performance transmission scheme. Our work focuses on Ray's core component: distributed in-memory object store named Plasma. We first identify the network bottleneck of Plasma
    through benchmarking and analysis. Then, we propose this scheme with hybrid transfer protocols.
    Besides the usual send/recv protocol, it has an extra one-sided read protocol for transferring
    large objects with zero-copy. For the best performance, we further implement a simple yet effective strategy to switch between the send-based and read-based protocols, given the sizes of the objects. Finally, we construct a distributed, scalable
    benchmark for testing the transmission overhead. Experiments demonstrate that, with the best-selected parameter, our improved memory store can achieve up to 7x throughput on our Tianhe HPC cluster.
}
% 英文文关键词(每个关键词之间用,分开, 最后一个关键词不打标点符号。)
\ekeywords{data transfer, high-performance network, RDMA, key-value database, distributed memory}